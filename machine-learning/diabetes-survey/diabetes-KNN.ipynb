{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlkÄ±m Ege Akarsu | 21901461 | EEE 485 | Term Project\n",
    "# Classification of Diabetic and Non-Diabetic Individuals Based on Survey Data\n",
    "# K-Nearest Neighbors\n",
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For math operations\n",
    "import pandas as pd  # For importing and handling datasets\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from mpl_toolkits.mplot3d import axes3d  # For 3D component of plotting\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET PREPARATION\n",
    "def train_test_split(dataset, train_fraction):\n",
    "    \"\"\"Split the dataset into train and test sets\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): All available data points.\n",
    "        Label and features as columns, Datapoints as rows.\n",
    "        train_fraction (float): Fraction of data\n",
    "        points to be added to the training set.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Training dataset\n",
    "        DataFrame: Test dataset\n",
    "    \"\"\"\n",
    "    # Randomly sample for train\n",
    "    train = dataset.sample(frac=train_fraction, axis=\"index\")\n",
    "    # Subtract train from original\n",
    "    test = dataset.drop(index=train.index)\n",
    "    # Reset indexes\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def mini_dataset(dataset, fraction):\n",
    "    \"\"\"Return a fraction of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): Original dataset. Has shape (n, p).\n",
    "        fraction (double): Fraction of dataset to return.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Smaller dataset. Has shape (n / fraction, p).\n",
    "    \"\"\"\n",
    "    return dataset.sample(frac=fraction,\n",
    "                          axis=\"index\",\n",
    "                          ignore_index=True)\n",
    "\n",
    "\n",
    "def standardize(train, test):\n",
    "    \"\"\"Standardize X matrices of train and test splits. Uses the mean and\n",
    "    standard deviation of the training set to standardize both training\n",
    "    and test sets. This prevents data leakage between training and test sets.\n",
    "\n",
    "    Args:\n",
    "        train (DataFrame): Training set.\n",
    "        test (DataFrame): Test set.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Standardized training set\n",
    "        DataFrame: Standardized test set\n",
    "    \"\"\"\n",
    "    # Get mean and standard deviation\n",
    "    mean = train.mean()\n",
    "    std = train.std()\n",
    "    # Get results\n",
    "    train_result = (train - mean) / std\n",
    "    test_result = (test - mean) / std\n",
    "\n",
    "    return train_result, test_result\n",
    "\n",
    "\n",
    "def range_scaling(train, test):\n",
    "    \"\"\"Scale X matrices of train and test splits. Uses the min and\n",
    "    max values of the training set to scale both training\n",
    "    and test sets. This prevents data leakage between training and test sets.\n",
    "\n",
    "    Args:\n",
    "        train (DataFrame): Training set.\n",
    "        test (DataFrame): Test set.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Standardized training set\n",
    "        DataFrame: Standardized test set\n",
    "    \"\"\"\n",
    "    # Get min and max values\n",
    "    min_val = train.min()\n",
    "    max_val = train.max()\n",
    "    # Get results\n",
    "    train_result = (train - min_val) / (max_val - min_val)\n",
    "    test_result = (test - min_val) / (max_val - min_val)\n",
    "\n",
    "    return train_result, test_result\n",
    "\n",
    "\n",
    "# K-NEAREST NEIGHBORS\n",
    "def get_minkowski_distance(X, row_index, p):\n",
    "    \"\"\"Calculate the minkowski distance between\n",
    "    a point and every point in X. INCLUDES THE POINT ITSELF.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        row_index (int): Index of point in X.\n",
    "        p (int): The power parameter\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Distances between the given point and every point in X.\n",
    "        Index [n] has the distance between the given point and point\n",
    "        at index n in X. Has shape (n,).\n",
    "    \"\"\"\n",
    "    # Get the point of interest\n",
    "    point = X[row_index]\n",
    "\n",
    "    # Calculate the Minkowski distance\n",
    "    distances = np.sum(np.abs(X - point)**p, axis=1)**(1/p)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def get_cosine_distance(X, row_index):\n",
    "    \"\"\"Calculate the cosine distance between\n",
    "    a point and every point in X. INCLUDES THE POINT ITSELF.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        row_index (int): Index of point in X.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Distances between the given point and every point in X.\n",
    "        Index [n] has the distance between the given point and point\n",
    "        at index n in X. Has shape (n,).\n",
    "    \"\"\"\n",
    "    # Get the point of interest\n",
    "    point = X[row_index]\n",
    "\n",
    "    # Normalize the vectors\n",
    "    X_norm = np.linalg.norm(X, axis=1)\n",
    "    point_norm = np.linalg.norm(point)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_similarities = np.dot(X, point) / (X_norm * point_norm)\n",
    "\n",
    "    # Convert cosine similarities to cosine distances\n",
    "    cosine_distances = 1 - cosine_similarities\n",
    "\n",
    "    return cosine_distances\n",
    "\n",
    "\n",
    "def get_chebyshev_distance(X, row_index):\n",
    "    \"\"\"Calculate the chebyshev distance between\n",
    "    a point and every point in X. INCLUDES THE POINT ITSELF.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        row_index (int): Index of point in X.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Distances between the given point and every point in X.\n",
    "        Index [n] has the distance between the given point and point\n",
    "        at index n in X. Has shape (n,).\n",
    "    \"\"\"\n",
    "    # Get the point of interest\n",
    "    point = X[row_index]\n",
    "\n",
    "    # Calculate the Chebyshev distance\n",
    "    distances = np.max(np.abs(X - point), axis=1)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def get_k_nearest_labels(X, y, k, get_distance, p_minkowski=None):\n",
    "    \"\"\"Get the labels of the k nearest neighbors of every point in X.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        y (ndarray): Labels. Has shape (n, 1).\n",
    "        k (int): Number of nearest neighbors.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        p_minkowski (optional(int)): Minkowski distance parameter.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Labels of the nearest neighbors. Has shape (n, k).\n",
    "    \"\"\"\n",
    "    # Initialize an empty ndarray to store the labels of the k nearest neighbors\n",
    "    nearest_labels = np.empty((X.shape[0], k))\n",
    "\n",
    "    # Iterate over each point in X\n",
    "    for i in range(X.shape[0]):\n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Point: {i}\\n\")\n",
    "        \n",
    "        # Calculate the distances from the point to all other points\n",
    "        if p_minkowski == None:\n",
    "            distances = get_distance(X, i)\n",
    "        else:\n",
    "            distances = get_distance(X, i, p_minkowski)\n",
    "\n",
    "        # Get the indices of the k nearest NEIGHBORS\n",
    "        nearest_indices = np.argsort(distances)[1 : k + 1]\n",
    "\n",
    "        # Get the labels of the k nearest neighbors\n",
    "        nearest_y = y[nearest_indices]\n",
    "\n",
    "        # Store the labels in the ndarray\n",
    "        nearest_labels[i, :] = nearest_y.ravel()\n",
    "\n",
    "    return nearest_labels\n",
    "\n",
    "\n",
    "def get_k_nearest_labels_point(X, y, k, row_index, get_distance, p_minkowski=None):\n",
    "    \"\"\"Get the labels of the k nearest neighbors of given row index.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        y (ndarray): Labels. Has shape (n, 1).\n",
    "        k (int): Number of nearest neighbors.\n",
    "        row_index (int): Index of point in X.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        p_minkowski (optional(int)): Minkowski distance parameter.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Labels of the nearest neighbors. Has shape (k, 1).\n",
    "    \"\"\"\n",
    "    # Calculate the distances from the point to all other points\n",
    "    if p_minkowski == None:\n",
    "        distances = get_distance(X, row_index)\n",
    "    else:\n",
    "        distances = get_distance(X, row_index, p_minkowski)\n",
    "\n",
    "    # Get the indices of the k nearest neighbors\n",
    "    nearest_indices = np.argsort(distances)[1 : k + 1]\n",
    "\n",
    "    # Get the labels of the k nearest neighbors\n",
    "    nearest_y = y[nearest_indices]\n",
    "\n",
    "    # Return the labels\n",
    "    return nearest_y.ravel()\n",
    "\n",
    "\n",
    "def get_weights(y):\n",
    "    \"\"\"Determine the weights of each class in relation to their frequency.\n",
    "    Class weights are inversely proportional to the frequency of each class.\n",
    "\n",
    "    Args:\n",
    "        y (ndarray): Labels. Has shape (n, 1).\n",
    "\n",
    "    Returns:\n",
    "        tuple(double, double): Weights of respective classes.\n",
    "    \"\"\"\n",
    "    # Count the occurrence of each label\n",
    "    counts = np.bincount(y.astype(\"int\").flatten())\n",
    "\n",
    "    # Get the total number of labels\n",
    "    total = y.shape[0]\n",
    "\n",
    "    # Determine the weights of each class in relation to their frequency\n",
    "    weight_of_0 = total / counts[0]\n",
    "    weight_of_1 = total / counts[1]\n",
    "\n",
    "    return (weight_of_0, weight_of_1)\n",
    "\n",
    "\n",
    "def get_k_value(X):\n",
    "    \"\"\"Returns the k value to be used for k-nearest neighbors.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "    \n",
    "    Returns:\n",
    "        int: k value\n",
    "    \"\"\"\n",
    "    # Optimal value of k is the square root of the number of points\n",
    "    k_opt = np.sqrt(X.shape[0])\n",
    "    # Return closest odd number\n",
    "    lower = int(k_opt) - int(k_opt) % 2 + 1\n",
    "    upper = lower + 2\n",
    "    return lower if k_opt - lower < upper - k_opt else upper\n",
    "\n",
    "\n",
    "def predict_from_same_set(X, y, k, weights, get_distance, weighted=True, p_minkowski=None):\n",
    "    \"\"\"Predict the class of every point (row) in X.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Feature matrix. Has shape (n, p).\n",
    "        y (ndarray): Labels. Has shape (n, 1).\n",
    "        k (int): Number of nearest neighbors.\n",
    "        weights (tuple(double, double)): Weights of respective classes.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        weighted (bool): If True, use weighted voting.\n",
    "        p_minkowski (optional(int)): Minkowski distance parameter.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Predicted labels. Has shape (n, 1).\n",
    "    \"\"\"\n",
    "    # Get the labels of the k nearest neighbors for each point in X\n",
    "    if p_minkowski == None:\n",
    "        nearest_labels = get_k_nearest_labels(X, y, k, get_distance)\n",
    "    else:\n",
    "        nearest_labels = get_k_nearest_labels(X, y, k, get_distance, p_minkowski)\n",
    "\n",
    "    # Initialize an empty ndarray to store the predicted labels\n",
    "    predicted_labels = np.empty(X.shape[0], dtype=np.uint8)\n",
    "\n",
    "    # Iterate over each point in X\n",
    "    for i in range(X.shape[0]):\n",
    "        # Get the labels of the k nearest neighbors for the point\n",
    "        labels = nearest_labels[i, :]\n",
    "\n",
    "        # Count the occurrence of each label\n",
    "        counts = np.bincount(labels.astype(\"int\"))\n",
    "        \n",
    "        # If weighted voting is enabled, multiply the counts by the weights\n",
    "        if weighted:\n",
    "            for j in range(counts.shape[0]):\n",
    "                counts[j] *= weights[j]\n",
    "\n",
    "        # Get the label with the highest occurrence\n",
    "        predicted_label = np.argmax(counts)\n",
    "\n",
    "        # Store the predicted label in the ndarray\n",
    "        predicted_labels[i] = predicted_label\n",
    "\n",
    "    return predicted_labels.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def predict_from_different_set(X_train, y_train, X_valid, y_valid, k, weights, get_distance, weighted=True, p_minkowski=None):\n",
    "    \"\"\"Predict the class of every point (row) in X_valid. Picks point from\n",
    "    X_valid and puts it in X_train for prediction.\n",
    "\n",
    "    Args:\n",
    "        X_train (ndarray): Training feature matrix. Has shape (n, p).\n",
    "        y_train (ndarray): Training labels. Has shape (n, 1).\n",
    "        X_valid (ndarray): Validation feature matrix. Has shape (m, p).\n",
    "        y_valid (ndarray): Validation labels. Has shape (m, 1).\n",
    "        k (int): Number of nearest neighbors.\n",
    "        weights (tuple(double, double)): Weights of respective classes.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        weighted (bool, optional): If True, use weighted voting.\n",
    "        p_minkowski (optional(int)): Minkowski distance parameter.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Predicted labels. Has shape (m, 1).\n",
    "    \"\"\"\n",
    "    # Initialize an empty ndarray to store the predicted labels\n",
    "    predicted_labels = np.empty(X_valid.shape[0], dtype=np.uint8)\n",
    "\n",
    "    # Iterate over each point in X_valid\n",
    "    for i in range(X_valid.shape[0]):\n",
    "        \n",
    "        # Append the point to the end of X_train\n",
    "        X = np.vstack((X_train, X_valid[i, :]))\n",
    "        y = np.vstack((y_train, y_valid[i, :]))\n",
    "\n",
    "        # Get the labels of the k nearest neighbors for the point\n",
    "        row_index = -1\n",
    "        if p_minkowski == None:\n",
    "            nearest_labels = get_k_nearest_labels_point(X, y, k, row_index, get_distance)\n",
    "        else:\n",
    "            nearest_labels = get_k_nearest_labels_point(X, y, k, row_index, get_distance, p_minkowski)\n",
    "\n",
    "        # Count the occurrence of each label\n",
    "        counts = np.bincount(nearest_labels.astype(\"int\"))\n",
    "        \n",
    "        # If weighted voting is enabled, multiply the counts by the weights\n",
    "        if weighted:\n",
    "            for j in range(counts.shape[0]):\n",
    "                counts[j] *= weights[j]\n",
    "\n",
    "        # Get the label with the highest occurrence\n",
    "        predicted_label = np.argmax(counts)\n",
    "\n",
    "        # Store the predicted label in the ndarray\n",
    "        predicted_labels[i] = predicted_label\n",
    "\n",
    "    return predicted_labels.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# MODEL EVALUATION\n",
    "def get_confusion_matrix(true, pred):\n",
    "    \"\"\"Calculate confusion matrix for performance evaluation.\n",
    "\n",
    "    Args:\n",
    "        true (ndarray): Array of true labels. Has shape (t, 1).\n",
    "        pred (ndarray): Array of predicted labels. Has shape (t, 1).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Confusion matrix\n",
    "        TN FP\n",
    "        FN TP\n",
    "    \"\"\"\n",
    "    result = np.zeros((2, 2))\n",
    "\n",
    "    for i in range(true.shape[0]):\n",
    "        result[true[i][0]][pred[i][0]] += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_accuracy(true, pred):\n",
    "    \"\"\"Calculate accuracy for performance evaluation.\n",
    "\n",
    "    Args:\n",
    "        true (ndarray): Array of true labels. Has shape (t, 1).\n",
    "        pred (ndarray): Array of predicted labels. Has shape (t, 1).\n",
    "\n",
    "    Returns:\n",
    "        double: Accuracy value.\n",
    "    \"\"\"\n",
    "    TN, FP, FN, TP = get_confusion_matrix(true, pred).ravel()\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "\n",
    "def get_precision(true, pred):\n",
    "    \"\"\"Calculate precision for performance evaluation.\n",
    "\n",
    "    Args:\n",
    "        true (ndarray): Array of true labels. Has shape (t, 1).\n",
    "        pred (ndarray): Array of predicted labels. Has shape (t, 1).\n",
    "\n",
    "    Returns:\n",
    "        double: Precision value.\n",
    "    \"\"\"\n",
    "    TN, FP, FN, TP = get_confusion_matrix(true, pred).ravel()\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "\n",
    "def get_recall(true, pred):\n",
    "    \"\"\"Calculate recall for performance evaluation.\n",
    "\n",
    "    Args:\n",
    "        true (ndarray): Array of true labels. Has shape (t, 1).\n",
    "        pred (ndarray): Array of predicted labels. Has shape (t, 1).\n",
    "\n",
    "    Returns:\n",
    "        double: Recall value.\n",
    "    \"\"\"\n",
    "    TN, FP, FN, TP = get_confusion_matrix(true, pred).ravel()\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "\n",
    "def get_f1_score(true, pred):\n",
    "    \"\"\"Calculate F1 score for performance evaluation.\n",
    "\n",
    "    Args:\n",
    "        true (ndarray): Array of true labels. Has shape (t, 1).\n",
    "        pred (ndarray): Array of predicted labels. Has shape (t, 1).\n",
    "\n",
    "    Returns:\n",
    "        double: F1 score.\n",
    "    \"\"\"\n",
    "    TN, FP, FN, TP = get_confusion_matrix(true, pred).ravel()\n",
    "    return (2 * TP) / ((2 * TP) + FP + FN)\n",
    "\n",
    "\n",
    "# HYPERPARAMETER TUNING\n",
    "def cross_validation(X_train, y_train, k, weights, get_distance, K, weighted=True, p_minkowski=None):\n",
    "    \"\"\"Evaluate model performance using K-fold cross-validation.\n",
    "\n",
    "    Args:\n",
    "        X_train (ndarray): Training feature matrix. Has shape (n, p).\n",
    "        y_train (ndarray): Training labels. Has shape (n, 1).\n",
    "        k (int): Number of nearest neighbors.\n",
    "        weights (tuple(double, double)): Weights of respective classes.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        K (int): Number of folds\n",
    "        weighted (bool, optional): If True, use weighted voting.\n",
    "        p_minkowski (optional(int)): Minkowski distance parameter.\n",
    "\n",
    "    Returns:\n",
    "        double: Mean F1 score of all K folds\n",
    "    \"\"\"\n",
    "    # Initialize f1 score storage\n",
    "    f1_scores = np.zeros(K)\n",
    "    # Split dataset into k folds\n",
    "    X_folds = np.array_split(X_train, K)\n",
    "    y_folds = np.array_split(y_train, K)\n",
    "    # Loop over folds\n",
    "    for i in range(K):\n",
    "        # Get validation set\n",
    "        X_validation_set = X_folds[i]\n",
    "        y_validation_set = y_folds[i]\n",
    "        # Get training set (list comprehension ftw)\n",
    "        X_training_set = np.concatenate([X_folds[j] for j in range(K) if j != i])\n",
    "        y_training_set = np.concatenate([y_folds[j] for j in range(K) if j != i])\n",
    "        # Validate model on validation set\n",
    "        if p_minkowski is None:\n",
    "            predictions = predict_from_different_set(X_training_set, y_training_set, X_validation_set, y_validation_set, k, weights, get_distance, weighted)\n",
    "        else:\n",
    "            predictions = predict_from_different_set(X_training_set, y_training_set, X_validation_set, y_validation_set, k, weights, get_distance, weighted, p_minkowski)\n",
    "        f1_score = get_f1_score(y_validation_set, predictions)\n",
    "        # Save F1 score\n",
    "        f1_scores[i] = f1_score\n",
    "    # Return average F1 score\n",
    "    return f1_scores.mean()\n",
    "\n",
    "\n",
    "def tune_minkowski(X_train, y_train, weights, K, p_values, k_values, weighted=True):\n",
    "    \"\"\"Try to find the best p and k values using grid search\n",
    "    and K-fold cross validation.\n",
    "    \n",
    "    Args:\n",
    "        X_train (ndarray): Training feature matrix. Has shape (n, p).\n",
    "        y_train (ndarray): Training labels. Has shape (n, 1).\n",
    "        weights (tuple(double, double)): Weights of respective classes.\n",
    "        K (int): Number of folds\n",
    "        p_values (ndarray of ints): List of p values to try.\n",
    "        k_values (ndarray): List of k values to try.\n",
    "        weighted (bool, optional): If True, use weighted voting.\n",
    "\n",
    "    Returns:\n",
    "        tuple of ints: Best value of p, best value of k\n",
    "    \"\"\"\n",
    "    # Initialize results matrix\n",
    "    # 3 columns: p, k, score\n",
    "    results = np.empty((0, 3))\n",
    "    \n",
    "    # Perform grid search\n",
    "    # Loop over p\n",
    "    for p in p_values:\n",
    "        # Loop over k\n",
    "        for k in k_values:\n",
    "            # Print progress\n",
    "            print(f\"Grid search current values: p:{p}, k:{k}\\n\")\n",
    "            # Perform cross-validation\n",
    "            f1_score = cross_validation(X_train, y_train, k, weights, get_minkowski_distance, K, weighted, p)\n",
    "            # Append p, k, f1_score row to results matrix\n",
    "            row = np.array([p, k, f1_score])\n",
    "            results = np.vstack((results, row))\n",
    "    \n",
    "    p_results = results[:, 0].flatten()\n",
    "    k_results = results[:, 1].flatten()\n",
    "    f1_score_results = results[:, 2].flatten()\n",
    "    # Plot scores against p values\n",
    "    plt.plot(p_results, f1_score_results, \".\")\n",
    "    plt.title(\"Minkowsky: F1 Score vs Power Parameter\")\n",
    "    plt.xlabel(\"Power Parameter\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # # Plot scores against k values\n",
    "    # plt.plot(k_results, f1_score_results, \".\")\n",
    "    # plt.title(\"Minkowsky: F1 Score vs Neighbor Count\")\n",
    "    # plt.xlabel(\"Neighbor Count\")\n",
    "    # plt.ylabel(\"F1 Score\")\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    # # Plot scores against p values against k values\n",
    "    # plt.clf()\n",
    "    # ax = plt.figure().add_subplot(projection=\"3d\")\n",
    "    # # Plot the 3D surface\n",
    "    # ax.plot_trisurf(\n",
    "    #     p_results,\n",
    "    #     k_results,\n",
    "    #     f1_score_results,\n",
    "    #     edgecolor=\"royalblue\",\n",
    "    #     lw=0.5,\n",
    "    #     alpha=0.3,\n",
    "    # )\n",
    "    # ax.set(\n",
    "    #     xlabel=\"Power Parameter\",\n",
    "    #     ylabel=\"Neighbor Count\",\n",
    "    #     zlabel=\"F1 Score\",\n",
    "    # )\n",
    "    # plt.title(\"Minkowsky: F1 Score vs Power Parameter vs Neighbor Count\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Get p, k pair\n",
    "    # Row index of max score\n",
    "    row_index = np.argmax(results[:, 2])\n",
    "    best_row = results[row_index]\n",
    "    best_p = best_row[0]\n",
    "    best_k = best_row[1]\n",
    "\n",
    "    return best_p, best_k\n",
    "\n",
    "\n",
    "def tune_other_distance(X_train, y_train, weights, K, k_values, get_distance, weighted=True):\n",
    "    \"\"\"Try to find the best k value using grid search and K-fold cross validation.\n",
    "    \n",
    "    Args:\n",
    "        X_train (ndarray): Training feature matrix. Has shape (n, p).\n",
    "        y_train (ndarray): Training labels. Has shape (n, 1).\n",
    "        weights (tuple(double, double)): Weights of respective classes.\n",
    "        K (int): Number of folds\n",
    "        k_values (ndarray): List of k values to try.\n",
    "        get_distance (function): Distance function to be used.\n",
    "        weighted (bool, optional): If True, use weighted voting.\n",
    "\n",
    "    Returns:\n",
    "        int: Best value of k\n",
    "    \"\"\"\n",
    "    # Initialize results matrix\n",
    "    # 2 columns: k, score\n",
    "    results = np.empty((0, 2))\n",
    "    \n",
    "    # Perform grid search\n",
    "    # Loop over k\n",
    "    for k in k_values:\n",
    "        # Print progress\n",
    "        print(f\"Grid search current value: {k}\\n\")\n",
    "        # Perform cross-validation\n",
    "        f1_score = cross_validation(X_train, y_train, k, weights, get_distance, K, weighted)\n",
    "        # Append k, f1_score row to results matrix\n",
    "        row = np.array([k, f1_score])\n",
    "        results = np.vstack((results, row))\n",
    "    \n",
    "    k_results = results[:, 0].flatten()\n",
    "    f1_score_results = results[:, 1].flatten()\n",
    "    # Plot scores against k values\n",
    "    plt.plot(k_results, f1_score_results)\n",
    "    if get_distance == get_cosine_distance:\n",
    "        plt.title(\"Cosine: F1 Score vs Neighbor Count\")\n",
    "    else:\n",
    "        plt.title(\"Chebyshev: F1 Score vs Neighbor Count\")\n",
    "    plt.xlabel(\"Neighbor Count\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Get best k value\n",
    "    # Row index of max score\n",
    "    row_index = np.argmax(results[:, 1])\n",
    "    best_row = results[row_index]\n",
    "    best_k = best_row[0]\n",
    "\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype\n",
      "---  ------                --------------   -----\n",
      " 0   Diabetes              253680 non-null  uint8\n",
      " 1   HighBP                253680 non-null  uint8\n",
      " 2   HighChol              253680 non-null  uint8\n",
      " 3   CholCheck             253680 non-null  uint8\n",
      " 4   BMI                   253680 non-null  uint8\n",
      " 5   Smoker                253680 non-null  uint8\n",
      " 6   Stroke                253680 non-null  uint8\n",
      " 7   HeartDiseaseorAttack  253680 non-null  uint8\n",
      " 8   PhysActivity          253680 non-null  uint8\n",
      " 9   Fruits                253680 non-null  uint8\n",
      " 10  Veggies               253680 non-null  uint8\n",
      " 11  HvyAlcoholConsump     253680 non-null  uint8\n",
      " 12  AnyHealthcare         253680 non-null  uint8\n",
      " 13  NoDocbcCost           253680 non-null  uint8\n",
      " 14  GenHlth               253680 non-null  uint8\n",
      " 15  MentHlth              253680 non-null  uint8\n",
      " 16  PhysHlth              253680 non-null  uint8\n",
      " 17  DiffWalk              253680 non-null  uint8\n",
      " 18  Sex                   253680 non-null  uint8\n",
      " 19  Age                   253680 non-null  uint8\n",
      " 20  Education             253680 non-null  uint8\n",
      " 21  Income                253680 non-null  uint8\n",
      "dtypes: uint8(22)\n",
      "memory usage: 5.3 MB\n",
      "\n",
      "\n",
      "Number of data points in train set: 8118\n",
      "Number of data points in test set: 8118\n"
     ]
    }
   ],
   "source": [
    "# Import dataset into a pandas dataframe\n",
    "# Data points classified as \"diabetes or pre-diabetes\"(1) or \"no diabetes\"(0)\n",
    "dataset = pd.read_csv(\"datasets/binary.csv\", dtype=\"uint8\")\n",
    "# Dataset overview\n",
    "dataset.info(verbose=True, show_counts=True)\n",
    "\n",
    "# Divide dataset into training and test sets\n",
    "train_fraction = 0.8\n",
    "training, test = train_test_split(dataset, train_fraction)\n",
    "# Get smaller datasets (computationally unfeaseble otherwise)\n",
    "training = mini_dataset(training, 0.04)\n",
    "test = mini_dataset(test, 0.16)\n",
    "# Number of data points\n",
    "print(f\"\\n\\nNumber of data points in train set: {len(training.index)}\")\n",
    "print(f\"Number of data points in test set: {len(test.index)}\")\n",
    "\n",
    "# Get X and Y from train and test datasets\n",
    "# Train\n",
    "y_train = training[\"Diabetes\"]\n",
    "X_train = training.drop(\"Diabetes\", axis=1)\n",
    "# Test\n",
    "y_test = test[\"Diabetes\"]\n",
    "X_test = test.drop(\"Diabetes\", axis=1)\n",
    "\n",
    "# Standardize X\n",
    "X_train_standardized, X_test_standardized = standardize(X_train, X_test)\n",
    "# Range scale X\n",
    "X_train_scaled, X_test_scaled = range_scaling(X_train, X_test)\n",
    "\n",
    "# Convert everything from dataframe to ndarray and reshape\n",
    "# Train\n",
    "X_train_standardized = X_train_standardized.to_numpy()\n",
    "X_train_scaled = X_train_scaled.to_numpy()\n",
    "y_train = y_train.to_numpy().reshape(-1, 1)\n",
    "# Test\n",
    "X_test_standardized = X_test_standardized.to_numpy()\n",
    "X_test_scaled = X_test_scaled.to_numpy()\n",
    "y_test = y_test.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search current values: p:1, k:91\n",
      "\n",
      "Grid search current values: p:2, k:91\n",
      "\n",
      "Grid search current values: p:3, k:91\n",
      "\n",
      "Grid search current values: p:4, k:91\n",
      "\n",
      "Grid search current values: p:5, k:91\n",
      "\n",
      "Grid search current values: p:6, k:91\n",
      "\n",
      "Grid search current values: p:7, k:91\n",
      "\n",
      "Grid search current values: p:8, k:91\n",
      "\n",
      "Grid search current values: p:9, k:91\n",
      "\n",
      "Grid search current values: p:10, k:91\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minkowski distance F1 score: 0.4106213603214811\n",
      "Cosine distance F1 score: 0.395503223526041\n",
      "Chebyshev distance F1 score: 0.3547833305180646\n"
     ]
    }
   ],
   "source": [
    "# Things to tune:\n",
    "# distance metric\n",
    "# standardize vs scale: STANDARDIZE\n",
    "# p in minkowsky distance\n",
    "# k in k-nearest neighbors: k = sqrt(n)\n",
    "# weighted vs standard k-nearest neighbors algorithm: WEIGHTED\n",
    "\n",
    "# Tune minkowski distance\n",
    "weights = get_weights(y_train)\n",
    "p_values = np.arange(1, 11, 1)\n",
    "k = get_k_value(X_train_standardized)\n",
    "k_values = [k]\n",
    "best_p_minkowski, best_k_minkowski = tune_minkowski(X_train_standardized, y_train, weights, 10, p_values, k_values, weighted=True)\n",
    "# Tune cosine distance\n",
    "#k_values = np.arange(1, 301, 24)\n",
    "#best_k_cosine = tune_other_distance(X_train_standardized, y_train, weights, 10, k_values, get_cosine_distance, weighted=True)\n",
    "# Tune chebyshev distance\n",
    "#best_k_chebyshev = tune_other_distance(X_train_standardized, y_train, weights, 10, k_values, get_chebyshev_distance, weighted=True)\n",
    "\n",
    "# Evaluate minkowski distance model\n",
    "minkowski_score = cross_validation(X_train_standardized, y_train, k, weights, get_minkowski_distance, 10, weighted=True, p_minkowski=best_p_minkowski)\n",
    "# Evaluate cosine distance model\n",
    "cosine_score = cross_validation(X_train_standardized, y_train, k, weights, get_cosine_distance, 10, weighted=True)\n",
    "# Evaluate chebyshev distance model\n",
    "chebyshev_score = cross_validation(X_train_standardized, y_train, k, weights, get_chebyshev_distance, 10, weighted=True)\n",
    "# Print the results\n",
    "print(f\"Minkowski distance F1 score: {minkowski_score}\\n\"\n",
    "      f\"Cosine distance F1 score: {cosine_score}\\n\"\n",
    "      f\"Chebyshev distance F1 score: {chebyshev_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point: 0\n",
      "\n",
      "Point: 100\n",
      "\n",
      "Point: 200\n",
      "\n",
      "Point: 300\n",
      "\n",
      "Point: 400\n",
      "\n",
      "Point: 500\n",
      "\n",
      "Point: 600\n",
      "\n",
      "Point: 700\n",
      "\n",
      "Point: 800\n",
      "\n",
      "Point: 900\n",
      "\n",
      "Point: 1000\n",
      "\n",
      "Point: 1100\n",
      "\n",
      "Point: 1200\n",
      "\n",
      "Point: 1300\n",
      "\n",
      "Point: 1400\n",
      "\n",
      "Point: 1500\n",
      "\n",
      "Point: 1600\n",
      "\n",
      "Point: 1700\n",
      "\n",
      "Point: 1800\n",
      "\n",
      "Point: 1900\n",
      "\n",
      "Point: 2000\n",
      "\n",
      "Point: 2100\n",
      "\n",
      "Point: 2200\n",
      "\n",
      "Point: 2300\n",
      "\n",
      "Point: 2400\n",
      "\n",
      "Point: 2500\n",
      "\n",
      "Point: 2600\n",
      "\n",
      "Point: 2700\n",
      "\n",
      "Point: 2800\n",
      "\n",
      "Point: 2900\n",
      "\n",
      "Point: 3000\n",
      "\n",
      "Point: 3100\n",
      "\n",
      "Point: 3200\n",
      "\n",
      "Point: 3300\n",
      "\n",
      "Point: 3400\n",
      "\n",
      "Point: 3500\n",
      "\n",
      "Point: 3600\n",
      "\n",
      "Point: 3700\n",
      "\n",
      "Point: 3800\n",
      "\n",
      "Point: 3900\n",
      "\n",
      "Point: 4000\n",
      "\n",
      "Point: 4100\n",
      "\n",
      "Point: 4200\n",
      "\n",
      "Point: 4300\n",
      "\n",
      "Point: 4400\n",
      "\n",
      "Point: 4500\n",
      "\n",
      "Point: 4600\n",
      "\n",
      "Point: 4700\n",
      "\n",
      "Point: 4800\n",
      "\n",
      "Point: 4900\n",
      "\n",
      "Point: 5000\n",
      "\n",
      "Point: 5100\n",
      "\n",
      "Point: 5200\n",
      "\n",
      "Point: 5300\n",
      "\n",
      "Point: 5400\n",
      "\n",
      "Point: 5500\n",
      "\n",
      "Point: 5600\n",
      "\n",
      "Point: 5700\n",
      "\n",
      "Point: 5800\n",
      "\n",
      "Point: 5900\n",
      "\n",
      "Point: 6000\n",
      "\n",
      "Point: 6100\n",
      "\n",
      "Point: 6200\n",
      "\n",
      "Point: 6300\n",
      "\n",
      "Point: 6400\n",
      "\n",
      "Point: 6500\n",
      "\n",
      "Point: 6600\n",
      "\n",
      "Point: 6700\n",
      "\n",
      "Point: 6800\n",
      "\n",
      "Point: 6900\n",
      "\n",
      "Point: 7000\n",
      "\n",
      "Point: 7100\n",
      "\n",
      "Point: 7200\n",
      "\n",
      "Point: 7300\n",
      "\n",
      "Point: 7400\n",
      "\n",
      "Point: 7500\n",
      "\n",
      "Point: 7600\n",
      "\n",
      "Point: 7700\n",
      "\n",
      "Point: 7800\n",
      "\n",
      "Point: 7900\n",
      "\n",
      "Point: 8000\n",
      "\n",
      "Point: 8100\n",
      "\n",
      "Accuracy: 0.7124907612712491\n",
      "F1-score: 0.4256889763779528\n",
      "TN, FP, TP, FN: 4919.0, 2075.0, 865.0, 259.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get weights and k value\n",
    "weights = get_weights(y_test)\n",
    "k = get_k_value(X_test_standardized)\n",
    "# Make predictions\n",
    "trained_predictions = predict_from_same_set(X_test_standardized, y_test, k, weights, get_minkowski_distance, weighted=True, p_minkowski=best_p_minkowski)\n",
    "# Evaluate results\n",
    "trained_accuracy = get_accuracy(y_test, trained_predictions)\n",
    "trained_confusion_matrix = get_confusion_matrix(y_test, trained_predictions)\n",
    "trained_f1_score = get_f1_score(y_test, trained_predictions)\n",
    "TN, FP, FN, TP = get_confusion_matrix(y_test, trained_predictions).ravel()\n",
    "print(\n",
    "    f\"Accuracy: {trained_accuracy}\\n\"\n",
    "    f\"F1-score: {trained_f1_score}\\n\"\n",
    "    f\"TN, FP, TP, FN: {TN}, {FP}, {TP}, {FN}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
